# 1. (CGCL)《Candidate-aware Graph Contrastive Learning for Recommendation》

> SIGIR '23
>
> 关键词：推荐系统、图对比学习

## 背景

- 大部分基于GCL的方法都使用启发式的数据增强方法，如随机节点、边删除，这可能会导致重要信息的丢失。并且使用启发式的策略并不通用，需要根据具体任务人工挑选适合的方法。
- 现有基于GCL的方法忽略用户和候选商品在不同层嵌入表征的关系。
  - ![image-20231123152434970](../img/image-20231123152434970.png)

## 创新点

跨层跨side对比

- 不需要额外数据增强方法，只使用用户和候选商品在不同层的嵌入表征来构建对比视图
- 选取了三种对比视图方法，分别为基于结构邻居对比（自身和二阶邻居对比）、基于候选对比（自身和交互节点的一节邻居对比）和基于候选结构邻居对比（自身的二阶邻居和交互节点的一节邻居对比），从而设计了三个不同的对比损失函数来获取高质量节点表征

## 方法

![image-20231123164437532](../img/image-20231123164437532.png)

**假设**：在用户-商品交互图中，每一层的邻居节点信息都是相同的，并且这些同构用户(商品)节点通过卷积传播连接起来。同构节点可以被认为具有相似的语义信息，在嵌入空间中彼此会更接近。

> 以下论文给的公式、代码和论文里的阐述并不一样。笔者按照自己对作者的意图进行公式上的修改。
>
> 笔者只对用户侧的公式进行阐述，商品侧的公式同理可得到。

**part A**

- 建模结构邻居和中心节点的关系

  - 以中心节点自身的嵌入为锚点，中心节点的同构邻居节点嵌入为正例，其他中心节点的同构邻居节点嵌入为负例。

  - $$
    \mathcal{L}_S^U=\sum_{u\in\mathcal{U}}-\log\frac{\exp\left(sim\left(e_u^{(0)},e_u^{(2)}\right)/\tau\right)}{\sum_{v\in\mathcal{U}}\exp\left(sim\left(e_u^{(0)},e_v^{(2)}\right)/\tau\right)}.
    $$

  - 其中 $e_u^{(k)}$ 表示用户第 $ k$ 层GNN得到的嵌入表征。$\mathcal U$ 为全部的用户节点。

**part B**

- 建模用户和候选商品的关系

  - 如果用户$u$与候选商品$i$的交互，则该用户应与嵌入空间中候选商品的历史交互用户相似。此外，用户𝑢不应与嵌入空间中其他商品的历史交互用户相似。

  - 以用户 $u$ 的嵌入为锚点，候选商品 $i$ （与 $u$ 交互的商品）一阶邻居节点嵌入为正例，其他商品的一阶邻居节点嵌入为负例。

  - 
    $$
    \mathcal{L}_C^U=\sum_{u\in\mathcal{U}}-\log\frac{\sum_{i \in \mathcal I^+} \exp\left(sim\left(e_u^{(0)},e_i^{(1)}\right)/\tau\right)}{\sum_{j\in\mathcal{I}}\exp\left(sim\left(e_u^{(0)},e_j^{(1)}\right)/\tau\right)}.
    $$

  - 其中 $e_u^{(k)}$ 表示用户第 $ k$ 层GNN得到的嵌入表征。$\mathcal U$ 为全部的用户节点。$\mathcal I$ 和 $\mathcal I^+$ 分别表示为全部商品节点和与用户 $u$ 交互的商品节点。

**part C**

- 建模用户的结构邻居和候选商品的关系

  - 如果用户$u$与候选商品$i$交互，则该用户二阶邻居节点应与嵌入空间中候选商品的一阶邻居用户相似。此外，用户𝑢不应与嵌入空间中其他商品的历史交互用户相似。

  - 以用户 $u$ 的二阶邻居节点嵌入为锚点，候选商品 $i$ （与 $u$ 交互的商品）一阶邻居节点嵌入为正例，其他商品的一阶邻居节点嵌入为负例。

  - 
    $$
    \mathcal{L}_{CS}^U=\sum_{u\in\mathcal{U}}-\log\frac{\sum_{i \in \mathcal I^+} \exp\left(sim\left(e_u^{(2)},e_i^{(1)}\right)/\tau\right)}{\sum_{j\in\mathcal{I}}\exp\left(sim\left(e_u^{(2)},e_j^{(1)}\right)/\tau\right)}.
    $$

  - 其中 $e_u^{(k)}$ 表示用户第 $ k$ 层GNN得到的嵌入表征。$\mathcal U$ 为全部的用户节点。$\mathcal I$ 和 $\mathcal I^+$ 分别表示为全部商品节点和与用户 $u$ 交互的商品节点。

**优化**
$$
\mathcal{L}_{CGCL}=\mathcal{L}_{Rec}+\lambda_{1}\mathcal{L}_{S}+\lambda_{2}\mathcal{L}_{C}+\lambda_{3}\mathcal{L}_{CS}+\lambda_{4}\left\|\Theta\right\|_{2}^{2}.
$$

## 思考

论文阐述思想和列举的公式**不符**

- 作者利用不同层和不同side组合构造对比视图，具有一定创新性。但是这种组合的权值是由人工确定的，能否考虑使用自适应方法自动学习得到。作者只考虑三种组合方式，能否添加其他合理的组合方式。
- 结合公式和代码，可以确定作者使用的是全部节点构造负例，计算代价比较大
- 根据消融实验可以看出，使用A方法贡献是最大的，即针对同一节点的不同层嵌入进行对比学习。剩下两种方法贡献较少。
- 根据代码给的超参数值，发现在联合优化损失函数中，三个对比损失函数的权重都比较小，分别为1e-5, 1e-5, 1e-6。



# 2.（NCL）《Improving graph collaborative filtering with neighborhood-enriched contrastive learning》

> WWW '22
>
> 关键词：推荐系统、协同过滤、图对比学习

## 主要内容

为了构造更有意义的面向推荐领域的对比视图，作者考虑了用户商品交互图中节点的邻居关系信息——结构邻居信息和语义邻居信息，然后将节点和其同构邻居构成对比关系，将节点和通过聚类后的聚类中心构成对比关系，设计了两种对应的对比学习损失函数进行优化学习。其中，基于语义的对比学习中聚类过程无法进行端到端优化，因此使用EM算法进行优化学习。

## 背景



## 方法

> 该部分是参考PCL ([Prototypical contrastive learning of unsupervised representations](https://arxiv.org/abs/2005.04966))方法，并且讲的也不清晰，对此我会使用PCL论文内容补充

## 结果







# 参考文献

> 1. Wei He, Guohao Sun, Jinhu Lu, and Xiu Susie Fang. 2023. Candidate-aware Graph Contrastive Learning for Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23). Association for Computing Machinery, New York, NY, USA, 1670–1679. https://doi.org/10.1145/3539618.3591647
> 2. Lin Z, Tian C, Hou Y, et al. Improving graph collaborative filtering with neighborhood-enriched contrastive learning[C]//Proceedings of the ACM Web Conference 2022. 2022: 2320-2329.
> 2. Yonghui Yang, Zhengwei Wu, Le Wu, Kun Zhang, Richang Hong, Zhiqiang Zhang, Jun Zhou, and Meng Wang. 2023. Generative-Contrastive Graph Learning for Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23). Association for Computing Machinery, New York, NY, USA, 1117–1126. https://doi.org/10.1145/3539618.3591691

